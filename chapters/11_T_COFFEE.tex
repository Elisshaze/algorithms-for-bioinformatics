\graphicspath{{chapters/images/}}
\chapter{T-COFFEE}
T-COFFEE method is broadly based on the popular progressive approach to multiple alignment but avoids the most serious pitfalls caused by the greedy nature of this algorithm.  
By pre-processing a data set of all pair-wise alignments between the sequences, a library is built to guide the progressive alignment. 
Intermediate alignments are then based not only on the sequences to be aligned next, but also on how all of the sequences align with each other. This alignment information can be derived from heterogeneous sources such as a mixture of alignment programs and/or structure superposition. 

\section{Introduction}
The most commonly used heuristic methods are based on the progressive-alignment strategy, with ClustalW being the most widely used implementation. 
Although successful in a wide variety of cases, this method suffers from its greediness, as errors made in the first alignments cannot be rectified later as the rest of the sequences are added in. 
T-Coffee is an attempt to minimize that effect, and although being still a greedy progressive method, it allows for much better use of information in the early stages.
\\
\\
\noindent
The main alternative to progressive alignment is the simultaneous alignment of all the sequences. Two such packages exist (MSA and DCA), based on the Carrilo and Lipman algorithm, but they remain an extremely CPU and memory-intensive approach. 
Iterative strategies do not provide any guarantees about finding optimal solutions but are reasonably robust and much less sensitive to the number of sequences than their deterministic counterparts.
Alternatively, one might wish to consider local similarity, as occurs when two proteins share only a domain or motif.
Lalign, a variant of SW algorithm from the FASTA package, produces sets of non-overlapping local alignments from the comparison of two sequences. 
For multiple sequences, the Gibbs sampler and Dialign2 are the main automatic methods, which perform well when there is a clear block of ungapped alignment shared by all of the sequences. 
They perform poorly, however, on general sets of test cases when compared with global methods. 
T-Coffee is aimed at providing a simple,  flexible and, most importantly, accurate solution to the problem of how to combine global and local multiple alignments. 

\section{T-Coffee Algorithm}
T-Coffee (Tree-based Consistency Objective Function for alignment Evaluation) has two main features. First, it provides a simple and flexible means of generating multiple alignments, using heterogeneous data sources. The data from these sources are provided to T-Coffee via a library of pair-wise alignments. 
The second main feature is the optimization method, which is used to find the multiple alignment that best fits the pair-wise alignments in the input library. We use a so-called progressive strategy, which is similar to that used in ClustalW. T- Coffee is a progressive alignment with an ability to consider information from all of the sequences during each alignment step, not just those being aligned at that stage. The progressive alignment is speed and simple, and a lower tendency to make errors is observed.
An overall scheme of T-Coffee algorithm is reported in figure \ref{fig:tcoffee}.

\begin{figure}[ht]
		\centering
		\includegraphics[width=0.5\textwidth]{tcoffee}
		\caption{\label{fig:tcoffee}}
	\end{figure}
	
\subsection{Generating a primary library of alignments}
The primary library contains a set of pair-wise alignments between all of the sequences to be aligned. 
In the library, we include information on each of the $N(N - 1)/2$ sequence pairs, where $N$ is the number of sequences. 
\begin{itemize}
\item global alignments are computed with ClustalW
\item  local alignments are the ten top- scoring non-intersecting local alignments, between each pair of sequences, gathered using the Lalign
\end{itemize}
In the library, each alignment is represented as a list of pair-wise residue matches (e.g. residue x of sequence A is aligned with residue y of sequence B). In effect, each of these pairs is a constraint. All of these constraints are not equally important, some may come from parts of alignments that are more likely to be correct. We take this into account when computing the multiple alignment and give priority to the most reliable residue pairs by using a weighting scheme.

\subsection{Derivation of the primary library weights}
T-Coffee assigns a weight to each pair of aligned residues in the library. An ideal primary weight will reflect the correctness of a constraint. Sequence identity is used, as it is known to be a reasonable indicator of accuracy when aligning sequences with more than 30\% identity. This weighting scheme proved to be highly effective for a previous consistency-based objective function and has the advantage of great simplicity. 
Each constraint receives a weight equal to percent identity within the pair-wise alignment it comes from.

\subsection{Combination of the libraries}
ClustalW and Laling primary libraries are pooled in a simple process of addition. 
If any pair is duplicated between the two libraries, it is merged into a single entry that has a weight equal to the sum of the two weights. Otherwise, a new entry is created for the pair being considered. 
Pairs of residues that did not occur are not represented (by default they will be considered to have a weight of zero).
This primary library can be used directly to compute a multiple sequence alignment. 
For each pair of aligned residues in the library, we can assign a weight that reflects the degree to which those residues align consistently with residues from all the other sequences.

\subsection{Extending the library}
Fitting a set of weighted constraints into a multiple alignment is a well-known problem, formulated as an instance of the "maximum weight trace", an NP-complete problem. The genetic algorithm is robust but may require prohibitive computation time, while the graph-theory-based algorithm has a complexity only partially characterized and may fail in some cases for reasons that are difficult to predict.
The overall idea of the heuristic library extension algorithm is to combine information in such a manner that the final weight, for any pair of residues, reflects some of the information contained in the whole library. To do so, a triplet approach is used: the weight associated with a pair of residues will be the sum of all the weights gathered through the examination of all the triplets involving that pair. 
The more intermediate sequences supporting the alignment of that pair, the higher its weight. 
Extension will be carried out on each pair of residues of A and B. Once the operation is complete, sequence pair A and B will have gathered information from all the other sequences in the set.  The complete set of pairs constitutes the extended library. 
The worst-case complexity of this computation is $O(N^3L^2)$ with L being the average sequence length. However, this will only occur when all the included pair-wise alignments are totally inconsistent. In practice the complexity is close to $(O)N^3L$.

\subsection{Progressive alignment strategy}
This alignment uses the weights in the extended library above to align the residues in the two sequences. This pair of sequences is then fixed and any gaps that have been introduced cannot be shifted later. Then the next closest two sequences are aligned or a sequence is added to the existing alignment of the first two sequences, depending which is suggested by the guide tree. The next two closest sequences or pre-aligned group of sequences are always joined.,until all the sequences have been aligned. 
To align two groups of pre-aligned sequences the scores from the extended library are used, as before, but the average library scores in each column of existing alignment are taken.
The procedure does not require any additional parameters such as gap penalties, as the substitution values (the library weights) were computed on alignments where such penalties had already been applied.  Furthermore, high scoring segments that show consistency within the data set see their score enhanced by the extension to such a point that they become insensitive to gap penalties. In practice, this means that during the progressive phase, we use a dynamic-programming algorithm with gap-opening penalties and gap- extension penalties set to zero for aligning two sequences or two groups of pre-aligned sequences.

\section{Discussion}
T-Coffee is a new progressive method for sequence alignment. It can combine signals from heterogeneous sources (e.g. sequence-alignment programs, structure alignments, threading, manual alignment, motifs and specific constraints) into a unique consensus multiple sequence alignment. 
The combination of local and global alignments leads to a significant increase in alignment accuracy. 
The main difference from traditional progressive alignment methods is that, instead of using a substitution matrix for aligning the sequences, a position-specific scoring scheme is used (the extended library). Errors are less likely to occur during early stages of the progressive alignment. As a consequence, even though the paradigm "once a gap always a gap" remains true, misplacing gaps becomes much less likely.
The second important feature of T-Coffee is the combination of local and global information. The end-user benefits from the simplicity of the method and does not need to provide any extra parameter values.
\\
\\
\noindent
A key ingredient of the method is the primary weighting scheme.  The main reason why T-Coffee can tolerate small segments with high similarity is more likely to occur by chance is because short high-scoring segments are rarely consistent enough to have a strong effect on the position-specific scoring scheme after extension. 
Moreover, final alignments are processed using dynamic programming,making it less likely for misplaced high-scoring segments to affect the alignment. 
Although the protocol proposed here employs a minimal combination of local and global information, there is no theoretical limit to the number of methods that can be used. For instance, alignments from structural comparisons could be combined with sequence alignments. It is also possible to incorporate, in the library, information extracted from multiple alignments.
