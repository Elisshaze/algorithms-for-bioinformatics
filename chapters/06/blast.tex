\graphicspath{{chapters/06/images}}
\chapter{BLAST - Basic local alignment search tool}

\section{Introduction}

	\subsection{Abstract}
	Basic local alignment search tool is a new approach to rapid sequence comparison.
	It approximates alignments that optimize a measure of local similarity.
	The basic algorithm is simple and robust and can be implemented in a number of ways and applied in a variety of context.

	\subsection{Introduction}
	Classical alignment tools minimize the evolutionary distance or maximise the similarity between two compared sequences.
	The cost of this alignment is a measure of similarity.
	Dynamic programming algorithms are unfeasible due to the large searching space.
	Rapid heuristic algorithms can make the search faster, but the measure of similarity is not explicitly defined, like in the FASTP program.
	This approach however have been useful in identifying many distant but biologically significant relationships.
	BLAST employs a measure based on well-defined measure scores approximating the results obtained by dynamic programming, creating a process an order of magnitude faster than existing heuristic algorithms.

\section{Methods}

	\subsection{The maximal segment pair measure}
	Sequence similarity measures can be classified as global (the overall alignment is optimized, including large stretches of low similarity) or local (relatively conserved subsequences).
	Local measures are preferred for database searches, many of which begin with a matrix of similarity scores for all possible pairs of residues.
	Identities and conservative replacements have positive scores, while unlikely replacements have negative scores.
	For amino acid sequence comparisons PAM-120 is used.
	A sequence segment is a contiguous stretch of residues of any length and the similarity scores for two aligned segments of the same length is the sum of the similarity values for each pair of residues in them.

		\subsection{Maximal segment pair}
		A maximal segment pair MSP is defined as the highest scoring pair of identical length segments chosen from $2$ sequences.
		The boundaries are chosen as to maximise its score.
		This BLAST attempts to heuristically calculate, providing a measure of local similarity for any pair of sequences.
		A segment pair si locally maximal if its score cannot be improved either by extending or shortening both segments.
		BLAST can seek all locally maximal segment pairs with scores above a cutoff.

		\subsubsection{Tractability to mathematical analysis}
		The MSP score may be computed in time proportional to the product of their lengths using a dynamic programming algorithm.
		The statistical significance of the MSP can be estimated under a random sequence model.
		Moreover for any particular scoring matrix, the frequencies of paired residues in maximal segments can be estimated.

	\subsection{Rapid approximation of MSP scores}
	Because only a handful in a database of thousands of sequences will be homologous to the query, only the sequence entries with MSP scores over some cutoff score $S$ are of interest.
	These include those sharing highly significant similarity with the query and some borderlines.
	The biological significance of high scoring sequences may be inferred on the bases of the similarity score.

		\subsubsection{MSP score estimates}
		The highest MSP score $S$ at which chance similarities are likely to appear can be estimated.
		BLAST minimizes the time spent on sequence regions whose similarity with the query has little chance of exceeding this score.
		Let a word pair be a segment pair of fixed length $w$.
		The main strategy is to seek only segment pairs that contain a word pair with a score of at least $T$.
		Scanning through a sequence, whether it contains a word of length $w$ that can pair with the query with a score greater or equal to the threshold $T$ can be quickly assessed.
		Any such hit is extended to determine if it is contained within a segment pair whose score is greater than or equal to $S$.
		The lower $T$, the greater the chance that a segment pair with a score of at least $S$ will contain a word pair with a score of at least $T$.
		A small value for $T$ increase the number of hits and the execution time.
		Random simulation permits to select a threshold $T$ that balances execution time and precision.

	\subsection{Implementation}
	The algorithm consists of three steps: compiling a list of high-scoring words, scanning the database for hits and extending hits.
	This vary on whether the database contains proteins or DNA.
	For proteins the list consists of all words or $w-mers$ that score at least $T$ when compared to some word in the query sequence: a query word may be represented by no words in the list.
	For useful results 50 words in the list for every residue in the query sequence.

		\subsubsection{Scanning phase}
		The scanning phase consists of the search of a long sequence for all occurrences of certain short sequences.

			\paragraph{First approach}
			The first approach consist of mapping each word to an integer, so a word can be used as an index into an array.
			The $ith$ entry of such an array points the list of all occurrences in the query sequence for the $ith$ word.
			Each database word leads immediately to the corresponding hits.

			\paragraph{Second approach}
			The second approach uses a deterministic finite automaton or finite state machine: signal acceptance is done on transitions.
			This saved a factor in space and time proportional to the size of the alphabet.
			This yielded a program that ran faster.

		\subsubsection{Hit extension}
		Extending a hit to find a locally maximal segment pair containing it is straightforward.
		The process is terminated in one direction when a segment pair whose score falls a certain distance below the best score for shorter extension.
		The added inaccuracy is negligible.

		\subsubsection{DNA alignment}
		For DNA a simpler word list is used.
		A query sequence of length $n$ yields a list of $n-w+1$ words.
		The database is compressed packing $4$ nucleotides in a single byte using an auxiliary table to delimit the boundaries.
		Assuming $w\ge 11$ each hit must contain an $8$-mer hit that lies on a byte boundary.
		This can allow to scan the database byte-wise and increase the speed $4$-fold.

		\subsubsection{Dealing with locally biased composition and repeated sequence element}
		To deal with biased composition when the database is compressed tabulates of the frequencies of all $8$-tuples are produced.
		Those occurring more frequently are stored and used to filter uninformative words from the query.
		A search of sublibrary of repetitive elements is performed and the locations in the query of significant matches are stored.
		Words generated by these regions are removed from the query word list.
		Matches to the sublibrary are reported in the final outpuit.

\section{Results}

	\subsection{Performance of BLAST with random sequences}
	Given a set of probabilities for the occurrence of individual residue, $\lambda$ and $K$ are used to evaluate the statistical significance of MSP scores.
	When two random sequences of lengths $m$ and $n$ are compared, the probability of finding a segment pair with a score greater or equal to $S$ is:

	$$1-e^{-y}$$

	Where $y = Kmne^{-\lambda S}$.
	Using this formula the approximate score an MSP must have to be distinguishable from chance similarities found in this database can be computed.
	The probability of finding $c$ or more distinct segment pairs, all with a score of at least $S$ is:

	$$1-e^{-y}\sum\limits_{i=1}^{c-1}\frac{y^i}{i!}$$

	Two sequences that share several distinct regions can be detected as significantly related.

		\subsubsection{Distribution of high-scoring segment pairs}
		It is of interest to know what proportion of segment pairs with a given score contain a word pair of length $w$ with a score of at least $T$.
		For MSP arising from the comparison of random sequences a limiting distribution is provided.
		The probability $q$ that a segment pair will fail to contain a word pair with score $T$ should depend exponentially upon the score of the MSP.
		Because the frequencies of paired letters in MSP approaches a limiting distribution, the expected length of an MSP grows linearly with its score.
		The longer an MSP the more independent chances it has for containing a word with a score of at least $T$, implying that $q$ should decrease exponentially with increasing MSP score $S$.

	\subsection{The choice of work length and threshold parameters}

		\subsubsection{Time required to execute}
		The time required to execute BLAST is the sum of the times required to:

		\begin{multicols}{2}
			\begin{itemize}
				\item Compile a list of words that can score at least $T$ when compared with words from the query.
				\item Scan the database for hits.
				\item Extend all hits to seek segment pairs with scores exceeding the cutoff.
			\end{itemize}
		\end{multicols}

		The time for the last is proportional to the number of hits, which depends on $w$ and $T$.

		\subsubsection{Choice of $w$}
		Given a random protein model and a set of substitution scores it is simple to calculate the probability that two random words of length $w$ will have a score of at least $T$, or the probability of a hit arising from an arbitrary pair of words in the query and database.
		For a given level of sensitivity (chance of missing a MSP), $w$ can be chosen such that it minimizes the chance of a hit.
		The probability of a hit decrease for increasing $w$ for different levels of sensitivity.
		Maintaining a given level of sensitivity the time spent on the third step can be decreased increasing $w$.
		But this will increase time spent on step $1$ as it increase the number of words generated and the memory requirement.
		For protein searches the best compromise is a word size of four.

		\subsubsection{Choice of $T$}
		Reducing $T$ improves the approximation of MSP scores, but it increases execution time: more words are generated by the query sequence and there will be more hits.
		The number of words generated increases exponentially with decreasing $T$.

		\subsubsection{Expected time complexity of BLAST}
		The expected time computational complexity of BLAST is:

		$$aW + bN + \frac{cNW}{20^w}$$

		Where $W$ is the number of words generated, $N$ is the number of residues in the database and $a, b$ and $c$ are constants.
		The $W$ term accounts for compiling the word list, $N$ covers the database scan and $NW$ for the extension.
		Although $W$ increases exponentially with $T$, it increases linearly with the length of the query.
		$T=17$ is a good choice for the threshold.

		\subsubsection{Trade-off between accuracy and speed}
		Given a specific probability $q$ of missing a MSP with score $S$, the $T$ required is computed and so the execution time.

	\subsection{Performance of BLAST with homologous sequences}
	BLAST's great utility is for finding high-scoring MSP quickly.
	The overall performance depend upon the distribution of MSP scores for those sequences related on the query.
	The bulk of the MSP that are distinguishable from chance have a high enough score to be found readily even using relatively high values for $T$.
	In each instance the threshold $S$ is chosen to include scores in the borderline region.

	\subsection{Comparison of two long DNA sequences}
	With smaller values of $w$ more alignments are found.
	The use of a smaller $w$ provides no new information.
